{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "packages = ['torch', 'numpy', 'matplotlib', 'pillow', 'scikit-learn', 'pandas', 'torchvision', 'scipy']\n",
    "for package in packages:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "        print(f\"✓ {package} installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {package} failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094de629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from glob import glob\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0041ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 96\n",
    "\n",
    "def create_motion_blur_kernel(size=15, angle=45):\n",
    "    kernel = np.zeros((size, size))\n",
    "    center = size // 2\n",
    "    angle_rad = np.deg2rad(angle)\n",
    "    for i in range(size):\n",
    "        offset = i - center\n",
    "        x = int(center + offset * np.cos(angle_rad))\n",
    "        y = int(center + offset * np.sin(angle_rad))\n",
    "        if 0 <= x < size and 0 <= y < size:\n",
    "            kernel[y, x] = 1\n",
    "    kernel = kernel / (kernel.sum() + 1e-8)\n",
    "    return kernel\n",
    "\n",
    "def apply_motion_blur(image, kernel_size=15, angle=None):\n",
    "    if angle is None:\n",
    "        angle = np.random.uniform(0, 180)\n",
    "    kernel = create_motion_blur_kernel(kernel_size, angle)\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        blurred = np.zeros_like(image)\n",
    "        for c in range(3):\n",
    "            blurred[:, :, c] = convolve(image[:, :, c], kernel, mode='reflect')\n",
    "    else:\n",
    "        blurred = convolve(image, kernel, mode='reflect')\n",
    "    \n",
    "    return np.clip(blurred, 0, 1).astype(np.float32)\n",
    "\n",
    "\n",
    "class STL10DeblurDataset(Dataset):\n",
    "    def __init__(self, split='train', img_size=96, blur_kernel_size=11):\n",
    "        self.img_size = img_size\n",
    "        self.blur_kernel_size = blur_kernel_size\n",
    "        \n",
    "        print(f\"Downloading STL-10 {split} set...\")\n",
    "        stl10 = torchvision.datasets.STL10(\n",
    "            root='./data', \n",
    "            split='train' if split == 'train' else 'test',\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "        self.images = []\n",
    "        for img, _ in stl10:\n",
    "            self.images.append(img.permute(1, 2, 0).numpy().astype(np.float32))\n",
    "        \n",
    "        self.images = np.array(self.images)\n",
    "        print(f\"Loaded {len(self.images)} images from STL-10 {split} set ({img_size}x{img_size})\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sharp = self.images[idx]\n",
    "        \n",
    "        angle = np.random.uniform(0, 180)\n",
    "        kernel_size = np.random.randint(7, self.blur_kernel_size + 1)\n",
    "        blur = apply_motion_blur(sharp, kernel_size=kernel_size, angle=angle)\n",
    "        \n",
    "        sharp_tensor = torch.from_numpy(sharp).permute(2, 0, 1).float()\n",
    "        blur_tensor = torch.from_numpy(blur).permute(2, 0, 1).float()\n",
    "        \n",
    "        sharp_tensor = sharp_tensor * 2 - 1\n",
    "        blur_tensor = blur_tensor * 2 - 1\n",
    "        \n",
    "        return blur_tensor, sharp_tensor\n",
    "\n",
    "\n",
    "print(\"Loading STL-10 dataset (96x96 high-quality images with synthetic motion blur)...\")\n",
    "train_dataset = STL10DeblurDataset(split='train', img_size=IMG_SIZE, blur_kernel_size=15)\n",
    "test_dataset = STL10DeblurDataset(split='test', img_size=IMG_SIZE, blur_kernel_size=15)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE//2, shuffle=False)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(5):\n",
    "    blur, sharp = train_dataset[i]\n",
    "    axes[0, i].imshow(((sharp + 1) / 2).permute(1, 2, 0).numpy().clip(0, 1))\n",
    "    axes[0, i].set_title('Sharp')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(((blur + 1) / 2).permute(1, 2, 0).numpy().clip(0, 1))\n",
    "    axes[1, i].set_title('Motion Blurred')\n",
    "    axes[1, i].axis('off')\n",
    "plt.suptitle('STL-10 Training Pairs (Sharp vs Motion Blurred)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d440411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, k=4, s=2, p=1, norm=True, act=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [nn.Conv2d(in_c, out_c, k, s, p, bias=not norm)]\n",
    "        if norm:\n",
    "            layers.append(nn.InstanceNorm2d(out_c))\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        if act:\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, k=4, s=2, p=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_c, out_c, k, s, p),\n",
    "            nn.InstanceNorm2d(out_c),\n",
    "        ]\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_channels, 64, norm=False)\n",
    "        self.enc2 = ConvBlock(64, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512, norm=False)\n",
    "        \n",
    "        self.dec1 = DeconvBlock(512, 256, dropout=0.5)\n",
    "        self.dec2 = DeconvBlock(512, 128, dropout=0.5)\n",
    "        self.dec3 = DeconvBlock(256, 64)\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, in_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        \n",
    "        d1 = self.dec1(e4)\n",
    "        d1 = F.interpolate(d1, size=e3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        d2 = self.dec2(torch.cat([d1, e3], dim=1))\n",
    "        d2 = F.interpolate(d2, size=e2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        d3 = self.dec3(torch.cat([d2, e2], dim=1))\n",
    "        d3 = F.interpolate(d3, size=e1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        out = self.dec4(torch.cat([d3, e1], dim=1))\n",
    "        \n",
    "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return out\n",
    "\n",
    "\n",
    "G = Generator()\n",
    "print(\"Generator Architecture (U-Net with Skip Connections):\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in G.parameters()):,}\")\n",
    "\n",
    "test_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)\n",
    "test_output = G(test_input)\n",
    "print(f\"Input shape: {test_input.shape} -> Output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminatorNet(nn.Module):\n",
    "    def __init__(self, in_c=6):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_c, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 1, 4, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        combined = torch.cat([x, y], dim=1)\n",
    "        return self.model(combined)\n",
    "\n",
    "\n",
    "class MultiScalePatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_c=6):\n",
    "        super().__init__()\n",
    "        self.d1 = PatchDiscriminatorNet(in_c)\n",
    "        self.d2 = PatchDiscriminatorNet(in_c)\n",
    "    \n",
    "    def forward(self, x_blur, x_sharp):\n",
    "        out1 = self.d1(x_blur, x_sharp)\n",
    "        \n",
    "        blur_ds = F.interpolate(x_blur, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "        sharp_ds = F.interpolate(x_sharp, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "        out2 = self.d2(blur_ds, sharp_ds)\n",
    "        \n",
    "        return out1, out2\n",
    "\n",
    "\n",
    "D = MultiScalePatchDiscriminator()\n",
    "print(\"Multi-Scale PatchGAN Discriminator:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in D.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(pred, target):\n",
    "    return torch.mean((pred - target) ** 2)\n",
    "\n",
    "\n",
    "class VGGPerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features[:16]\n",
    "        for p in vgg.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.vgg = vgg\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = (x + 1) / 2\n",
    "        y = (y + 1) / 2\n",
    "        return torch.mean((self.vgg(x) - self.vgg(y)) ** 2)\n",
    "\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return torch.tensor(100.0)\n",
    "    pixel_max = 1.0\n",
    "    return 20 * torch.log10(pixel_max / torch.sqrt(mse))\n",
    "\n",
    "\n",
    "print(\"Loss Functions initialized: GAN Loss, VGG Perceptual Loss, L1 Loss, PSNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "D = MultiScalePatchDiscriminator().to(device)\n",
    "vgg_loss = VGGPerceptualLoss().to(device)\n",
    "\n",
    "lr_G = 1e-4\n",
    "lr_D = 1e-4\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
    "\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=50, gamma=0.5)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=50, gamma=0.5)\n",
    "\n",
    "l1_criterion = nn.L1Loss()\n",
    "\n",
    "print(\"Models initialized:\")\n",
    "print(f\"Generator params: {sum(p.numel() for p in G.parameters()):,}\")\n",
    "print(f\"Discriminator params: {sum(p.numel() for p in D.parameters()):,}\")\n",
    "print(f\"Learning rates - G: {lr_G}, D: {lr_D}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b1a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "history = {'d_loss': [], 'g_loss': [], 'psnr': [], 'l1': []}\n",
    "\n",
    "lambda_l1 = 100.0\n",
    "lambda_vgg = 0.01\n",
    "lambda_gan = 1.0\n",
    "\n",
    "print(f\"Loss weights: L1={lambda_l1}, VGG={lambda_vgg}, GAN={lambda_gan}\")\n",
    "print(f\"Training for {num_epochs} epochs...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    G.train()\n",
    "    D.train()\n",
    "    \n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    epoch_psnr = 0.0\n",
    "    epoch_l1 = 0.0\n",
    "    \n",
    "    for blur, sharp in train_loader:\n",
    "        blur = blur.to(device)\n",
    "        sharp = sharp.to(device)\n",
    "        \n",
    "        opt_D.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_sharp = G(blur)\n",
    "        \n",
    "        real_out1, real_out2 = D(blur, sharp)\n",
    "        fake_out1, fake_out2 = D(blur, fake_sharp)\n",
    "        \n",
    "        real_label1 = torch.ones_like(real_out1).to(device) * 0.9\n",
    "        real_label2 = torch.ones_like(real_out2).to(device) * 0.9\n",
    "        fake_label1 = torch.zeros_like(fake_out1).to(device) + 0.1\n",
    "        fake_label2 = torch.zeros_like(fake_out2).to(device) + 0.1\n",
    "        \n",
    "        d_loss_real = gan_loss(real_out1, real_label1) + gan_loss(real_out2, real_label2)\n",
    "        d_loss_fake = gan_loss(fake_out1, fake_label1) + gan_loss(fake_out2, fake_label2)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        \n",
    "        d_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(D.parameters(), max_norm=1.0)\n",
    "        opt_D.step()\n",
    "        \n",
    "        opt_G.zero_grad()\n",
    "        \n",
    "        fake_sharp = G(blur)\n",
    "        \n",
    "        fake_out1, fake_out2 = D(blur, fake_sharp)\n",
    "        target_real1 = torch.ones_like(fake_out1).to(device)\n",
    "        target_real2 = torch.ones_like(fake_out2).to(device)\n",
    "        \n",
    "        g_gan = gan_loss(fake_out1, target_real1) + gan_loss(fake_out2, target_real2)\n",
    "        g_vgg = vgg_loss(fake_sharp, sharp)\n",
    "        g_l1 = l1_criterion(fake_sharp, sharp)\n",
    "        \n",
    "        g_loss = lambda_gan * g_gan + lambda_vgg * g_vgg + lambda_l1 * g_l1\n",
    "        \n",
    "        g_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(G.parameters(), max_norm=1.0)\n",
    "        opt_G.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_psnr = psnr((fake_sharp + 1) / 2, (sharp + 1) / 2)\n",
    "        \n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_loss.item()\n",
    "        epoch_psnr += batch_psnr.item()\n",
    "        epoch_l1 += g_l1.item()\n",
    "    \n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    epoch_d_loss /= n_batches\n",
    "    epoch_g_loss /= n_batches\n",
    "    epoch_psnr /= n_batches\n",
    "    epoch_l1 /= n_batches\n",
    "    \n",
    "    history['d_loss'].append(epoch_d_loss)\n",
    "    history['g_loss'].append(epoch_g_loss)\n",
    "    history['psnr'].append(epoch_psnr)\n",
    "    history['l1'].append(epoch_l1)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1:3d}/{num_epochs}] D_loss: {epoch_d_loss:.4f} | G_loss: {epoch_g_loss:.4f} | L1: {epoch_l1:.4f} | PSNR: {epoch_psnr:.2f} dB\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085486cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(history['d_loss'], label='Discriminator')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Discriminator Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].plot(history['g_loss'], label='Generator', color='orange')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Generator Loss')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "axes[1, 0].plot(history['l1'], label='L1', color='red')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('L1 Loss')\n",
    "axes[1, 0].set_title('L1 Reconstruction Loss')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "axes[1, 1].plot(history['psnr'], label='PSNR', color='green')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('PSNR (dB)')\n",
    "axes[1, 1].set_title('Training PSNR')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "\n",
    "test_results = []\n",
    "all_psnr_blur = []\n",
    "all_psnr_deblur = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(min(10, len(test_dataset))):\n",
    "        blur, sharp = test_dataset[i]\n",
    "        blur = blur.unsqueeze(0).to(device)\n",
    "        sharp = sharp.unsqueeze(0).to(device)\n",
    "        \n",
    "        fake_sharp = G(blur)\n",
    "        \n",
    "        blur_01 = (blur + 1) / 2\n",
    "        sharp_01 = (sharp + 1) / 2\n",
    "        fake_01 = (fake_sharp.squeeze(0) + 1) / 2\n",
    "        \n",
    "        psnr_blur = psnr(blur_01, sharp_01).item()\n",
    "        psnr_deblur = psnr(fake_01, sharp_01).item()\n",
    "        \n",
    "        all_psnr_blur.append(psnr_blur)\n",
    "        all_psnr_deblur.append(psnr_deblur)\n",
    "        \n",
    "        test_results.append({\n",
    "            'Image': i + 1,\n",
    "            'PSNR Blurred': f'{psnr_blur:.2f}',\n",
    "            'PSNR Deblurred': f'{psnr_deblur:.2f}',\n",
    "            'Improvement': f'{psnr_deblur - psnr_blur:+.2f}'\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(test_results)\n",
    "print(\"Test Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Average PSNR (Blurred):   {np.mean(all_psnr_blur):.2f} dB\")\n",
    "print(f\"Average PSNR (Deblurred): {np.mean(all_psnr_deblur):.2f} dB\")\n",
    "print(f\"Average Improvement:      {np.mean(all_psnr_deblur) - np.mean(all_psnr_blur):+.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "\n",
    "n_samples = min(5, len(test_dataset))\n",
    "fig, axes = plt.subplots(3, n_samples, figsize=(3*n_samples, 9))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(n_samples):\n",
    "        blur, sharp = test_dataset[i]\n",
    "        blur_input = blur.unsqueeze(0).to(device)\n",
    "        \n",
    "        fake_sharp = G(blur_input)\n",
    "        \n",
    "        blur_np = ((blur + 1) / 2).permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
    "        fake_np = ((fake_sharp.squeeze(0) + 1) / 2).permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
    "        sharp_np = ((sharp + 1) / 2).permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
    "        \n",
    "        axes[0, i].imshow(blur_np)\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel('Blurred', fontsize=12)\n",
    "        \n",
    "        axes[1, i].imshow(fake_np)\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('Deblurred', fontsize=12)\n",
    "        \n",
    "        axes[2, i].imshow(sharp_np)\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].set_ylabel('Ground Truth', fontsize=12)\n",
    "\n",
    "plt.suptitle('DeblurGAN Results: Blurred → Deblurred → Ground Truth', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'deblur_gan_model.pth'\n",
    "torch.save({\n",
    "    'generator': G.state_dict(),\n",
    "    'discriminator': D.state_dict(),\n",
    "    'history': history,\n",
    "    'config': {\n",
    "        'img_size': IMG_SIZE,\n",
    "        'lambda_l1': lambda_l1,\n",
    "        'lambda_vgg': lambda_vgg,\n",
    "        'lambda_gan': lambda_gan,\n",
    "    }\n",
    "}, save_path)\n",
    "print(f\"Model saved to {save_path}\")\n",
    "print(f\"Final PSNR: {history['psnr'][-1]:.2f} dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
